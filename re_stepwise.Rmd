---
title: "Report Exercise Chapter 8"
author: "Samuel Bichsel"
output: html_document
---

## About this file 

This Markdown file is for the report exercise of Chapter 8 (Regression and Classification) of the AGDS Course. The goal of the Exercise is to implement an Algorithm for stepwise forward regression to model GPP in the dataset of half-hourly fluxes. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, fig.width=4, fig.height=3)

```

```{r} 
FLUXNET <-  readr::read_csv("./data/df_for_stepwise_regression.csv")
library(ggplot2)
library(tidyverse)
library(tidyr)
library(yardstick)

```

## Step 1: Evaluation of all bivariate models (single predictor)

Step 1: all bivariate models (single predictor), steps 1-3 of algorithm

```{r}
models <- list()
RSQUARED <- c()
#empty lists to put the models, the summaries of the regressions, and the AICs of the models into

predictors_i <- colnames(FLUXNET)[3:17]
predictors_i = predictors_i[predictors_i != "GPP_NT_VUT_REF"]


for (i in 1:length(predictors_i)){ 
  
  models[[i]] <- 
    lm(FLUXNET$GPP_NT_VUT_REF ~., FLUXNET[ , predictors_i[i]])
  RSQUARED[i] <- summary(models[[i]])$adj.r.squared
}

bestfitting <- models[[which.max(RSQUARED)]]

bestmodel <- c(predictors_i[which.max(RSQUARED)],
               RSQUARED[which.max(RSQUARED)],
               extractAIC(bestfitting)[2])
bestmodel

```

The best model is the one using PPFD_IN (Incoming photosynthetic photon flux density) as a predictor. The adjusted R-Squared is 0.452, meaning 45.2% of the variability in GPP can be explained by the Regression model with the PPFD variable. 


### plots
```{r}

plots <- list()
#empty list for the plots to be put into


xlabels <- expression("Air Temperature (°C)", 
                paste("Shortwave radiation (W m"^-2, ")"),
                paste("Longwave radiation (W m"^-2, ")"), 
                "Vapor Pressure deficit (hPa)", 
                "Atmospheric Pressure (kPa)", "Precipitation(mm)",
                paste("Wind Speed (m s"^-1, ")"), 
                "Air Temperature (°C), MDS-Gapfilled", 
                paste("Shortwave radiation (W m"^-2, "), MDS-Gapfilled"),
                paste("Longwave radiation (W m"^-2, "), MDS-Gapfilled"),
                "Vapor Pressure deficit (hPa), MDS-Gapfilled",
                paste("CO"[2], "mole fraction(mol CO"[2], " m"^-2, "s"^-1,                    ")MDS-Gapfilled"), 
                paste("Incoming PPFD (", mu, "mol Photon m"^-2, "s"^-1,")"
                ),
                paste("Friction velocity (m ", "s"^-1, ")"))

#list of the labels to be used 


for (i in 1:length(predictors_i)){

  plots[[i]] <- ggplot(
    data = FLUXNET, 
    aes_string(x = predictors_i[i], y = "GPP_NT_VUT_REF")) +
    geom_point() +
    geom_smooth(method = "lm", color = "red") + 
    labs (title = predictors_i[i],
          x = xlabels[i],
          y =  expression(paste("GPP (", mu,"mol CO"[2], " m"^-2, "s"^-1, ")"))) 
    
}

cowplot::plot_grid(plots[1], plots[2], ncol = 4)
plots 
#on a sidenote, I couldn't get cowplot to work in order to arrange the plots (it always resulted in a blank square), so the plots take up a looot more space than I would've liked :(

```

As can be seen from the summaries as well as the graphics, the best R-Squared is the one for the bivariate model using PPFD_IN (Incoming photosynthetic photon flux density) as a single predictor for the GPP (0.452). This means 45.2% of the variability in GPP can be explained by the Regression model with the PPFD_IN variable.


## Step 2: stepwise forward regression  

```{r}


used_var <- list()
var_selection <- list()
RSQUARED <- list()
models1 <- list()
AICS <- c()
optimal_model <- c()

#set up list of predictors to be used & predictors being used
predictors_i <- colnames(FLUXNET)[3:17]
predictors_i = predictors_i[predictors_i != "GPP_NT_VUT_REF"]


GPP <- FLUXNET$GPP_NT_VUT_REF

for (i in 1:14){
  
  #inside loop, going through all variables that are still left, computing the R2 of them + the used variables and computing the R2 for all of them
  for (j in 1:length(predictors_i)){
    var_selection[[j]]<- lm(
      as.formula(paste("GPP ~", paste(c(used_var, 
      predictors_i[[j]]), collapse="+"))), 
      data = FLUXNET) 
    RSQUARED[j] <- summary(var_selection[[j]])$adj.r.squared 
  }
  RSQUARED <- as.numeric(RSQUARED)
  x <- which.max(RSQUARED) #which variable gives the biggest R2 
  used_var[[i]] <-  predictors_i[x]
  predictors_i <- predictors_i[-x] #remove the used variables from the list of available variables
  RSQUARED <- RSQUARED[-x]
  
  models1[[i]] <- lm(formula = 
      as.formula(paste("GPP ~", paste(used_var, collapse="+"))), data = FLUXNET) 
  AICS[i] <- as.numeric(extractAIC(models1[[i]])[2])
  
  print((lapply(models1, summary)[i]))
  
  
  if(length(AICS) > 1){
     if(AICS[i] > AICS[i-1])
       
       break}
  
}
optimal_model <- models1[i-1]
lapply(optimal_model, summary) 
AICS[i-1]

#optimal model has to be at spot i-1 because the loop goes until the AICS of the model is worse than the previous one, meaning the last model will be slightly worse than the one right before 

#var_selection is a list of all lm models that we can choose from. used_var is all the variables already used in the previous steps of the algorithms, and with the inner loop j and predictors_i[j] we test that old model + every variable not used yet and keep the best one


```

The optimal model uses 11 of the 14 independent variables, with an adjusted R-Squared of 0.5964 and an AICS of 27397.68. Most variables are statistically significant at the 0.1% level. The 3 variables that were not used are all MDS Gap filled, which makes sense as to why they are not being used since they are very close to the non-gap filled variables and thus barely or not at all explain more variation. 